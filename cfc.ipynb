{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9731164-eec4-464b-9409-c108dc226e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-17 12:44:07.569428: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-17 12:44:07.624044: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-17 12:44:07.624090: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-17 12:44:07.625508: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-17 12:44:07.634583: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-17 12:44:08.735041: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/jagat/anaconda3/envs/lnn/lib/python3.10/site-packages/ray/tune/logger/tensorboardx.py:35: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  VALID_NP_HPARAMS = (np.bool8, np.float32, np.float64, np.int32, np.int64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "import tensorflow as tf\n",
    "\n",
    "# import gymnasium\n",
    "import ale_py\n",
    "from ray.rllib.env.wrappers.atari_wrappers import wrap_deepmind\n",
    "from ncps.tf import CfC\n",
    "import numpy as np\n",
    "from ncps.datasets.tf import AtariCloningDatasetTF\n",
    "import gym\n",
    "import os \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Not used in this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a9d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(tf.keras.models.Sequential):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__(\n",
    "            [\n",
    "                tf.keras.Input((84, 84, 4)),\n",
    "                tf.keras.layers.Lambda(\n",
    "                    lambda x: tf.cast(x, tf.float32) / 255.0\n",
    "                ),  # normalize input\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    64, 5, padding=\"same\", activation=\"relu\", strides=2\n",
    "                ),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    128, 5, padding=\"same\", activation=\"relu\", strides=2\n",
    "                ),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    128, 5, padding=\"same\", activation=\"relu\", strides=2\n",
    "                ),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    256, 5, padding=\"same\", activation=\"relu\", strides=2\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "class ImpalaConvLayer(tf.keras.models.Sequential):\n",
    "    def __init__(self, filters, kernel_size, strides, padding=\"valid\",first = None, use_bias=False):\n",
    "        \n",
    "        if first == None:\n",
    "            y = tf.keras.layers.Conv2D(\n",
    "                    filters=filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    strides=strides,\n",
    "                    padding=padding,\n",
    "                    use_bias=use_bias,\n",
    "                    kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "                        scale=2.0, mode=\"fan_out\", distribution=\"truncated_normal\"\n",
    "                    ),\n",
    "                )\n",
    "        else: \n",
    "            y =  tf.keras.layers.Conv2D(\n",
    "                    filters=filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    strides=strides,\n",
    "                    padding=padding,\n",
    "                    use_bias=use_bias,\n",
    "                    kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "                        scale=2.0, mode=\"fan_out\", distribution=\"truncated_normal\"\n",
    "                    ),\n",
    "                    batch_input_shape = first\n",
    "                )\n",
    "        super(ImpalaConvLayer, self).__init__(\n",
    "            [\n",
    "                y,\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.99, epsilon=0.001),\n",
    "                tf.keras.layers.ReLU(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "class ImpalaConvBlock(tf.keras.models.Sequential):\n",
    "    def __init__(self):\n",
    "        super(ImpalaConvBlock, self).__init__(\n",
    "            [\n",
    "                ImpalaConvLayer(filters=16, kernel_size=8, strides=4,first= None),\n",
    "                ImpalaConvLayer(filters=32, kernel_size=4, strides=2,first= None),\n",
    "                ImpalaConvLayer(filters=32, kernel_size=3, strides=1,first= None),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(units=256, activation=\"relu\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "class ConvCFC(tf.keras.Model):\n",
    "    def __init__(self, n_actions, units = 4, mixed_memory=False, go_backwards=False, stateful=False,backbone_units=128, backbone_layers=1, backbone_dropout=0):\n",
    "        super().__init__()\n",
    "        self.mixed_memory = mixed_memory\n",
    "        self.conv_block = ImpalaConvBlock()\n",
    "        self.td_conv = tf.keras.layers.TimeDistributed(self.conv_block)\n",
    "        # EDIT : 1  \n",
    "        self.rnn = CfC(units=units, \n",
    "                       mixed_memory=mixed_memory, \n",
    "                       go_backwards=go_backwards, \n",
    "                       stateful=stateful,\n",
    "                       backbone_units=backbone_units, \n",
    "                       backbone_layers=backbone_layers, \n",
    "                       backbone_dropout=backbone_dropout,\n",
    "                       return_sequences=True, \n",
    "                       return_state=True)\n",
    "        self.linear = tf.keras.layers.Dense(n_actions)\n",
    "\n",
    "\n",
    "    def get_initial_states(self, batch_size=1):\n",
    "        return self.rnn.cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x, training=None, **kwargs):\n",
    "        has_hx = isinstance(x, list) or isinstance(x, tuple)\n",
    "        initial_state = None\n",
    "        if has_hx:\n",
    "            # additional inputs are passed as Copyright 2022 Mathias Lechner a tuple\n",
    "            x, initial_state = x\n",
    "\n",
    "        x = self.td_conv(x, training=training)\n",
    "\n",
    "        if self.mixed_memory:\n",
    "            x,_,next_state = self.rnn(x, initial_state=initial_state)\n",
    "        else:\n",
    "            x,next_state = self.rnn(x, initial_state=initial_state)\n",
    "\n",
    "        x = self.linear(x)\n",
    "        if has_hx:\n",
    "            return (x, next_state)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df10ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_closed_loop(model, env, num_episodes=None):\n",
    "    obs = env.reset()\n",
    "    hx = model.get_initial_states()\n",
    "    returns = []\n",
    "    total_reward = 0\n",
    "    while True:\n",
    "        # add batch and time dimension (with a single element in each)\n",
    "        obs = np.expand_dims(np.expand_dims(obs, 0), 0)\n",
    "        pred, hx = model.predict((obs, hx), verbose=0)\n",
    "        action = pred[0, 0].argmax()\n",
    "        # remove time and batch dimension -> then argmax\n",
    "        # obs, r, term, trunc, _ = env.step(action)\n",
    "        # done = term or trunc\n",
    "        obs, r, done, _ = env.step(action)\n",
    "        total_reward += r\n",
    "        if done:\n",
    "            returns.append(total_reward)\n",
    "            total_reward = 0\n",
    "            obs = env.reset()\n",
    "            hx = model.get_initial_states()\n",
    "            # Reset RNN hidden states when episode is over\n",
    "            if num_episodes is not None:\n",
    "                # Count down the number of episodes\n",
    "                num_episodes = num_episodes - 1\n",
    "                if num_episodes == 0:\n",
    "                    return returns\n",
    "            if num_episodes is None:\n",
    "                print(\n",
    "                    f\"Return {returns[-1]:0.2f} [{np.mean(returns):0.2f} +- {np.std(returns):0.2f}]\"\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5484be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def register_metrics(LR,\n",
    "                    batch_size, \n",
    "                    epochs, \n",
    "                    epoch, \n",
    "                    mixed_memory, \n",
    "                    go_backwards, \n",
    "                    stateful, \n",
    "                    hidden_size, \n",
    "                    backbone_units, \n",
    "                    backbone_layers, \n",
    "                    backbone_dropout,\n",
    "                    loss, \n",
    "                    accuracy, \n",
    "                    precision_score, \n",
    "                    f1, \n",
    "                    recall,\n",
    "                    file_path=\"cfc_multi_exp.csv\"):\n",
    "    import os\n",
    "    import csv\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        # File does not exist, create it\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\n",
    "                \"Learing rate\", \"batch_size\", \"epochs\", \"current_epoch\", \"mixed_memory\", \n",
    "                \"go_backwards\", \"stateful\", \"hidden_size\", \"backbone_units\", \n",
    "                \"backbone_layers\", \"backbone_dropout\", \"loss\", \n",
    "                \"accuracy\", \"precision_score\", \"f1\", \"recall\"\n",
    "            ])\n",
    "        print(f'CSV file \"{file_path}\" created.')\n",
    "\n",
    "    with open(file_path, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write a new row\n",
    "        writer.writerow([\n",
    "            LR, batch_size, epochs, epoch, mixed_memory, go_backwards, stateful, \n",
    "            hidden_size,backbone_units, backbone_layers, backbone_dropout,\n",
    "            loss, accuracy, precision_score, f1, recall\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d58d831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO\n",
    "class EvalCSVCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,model,valloader,inp_data,loss_fxn):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.valloader = valloader\n",
    "        self.inp_data = inp_data\n",
    "        self.loss_fxn = loss_fxn\n",
    "\n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        self.model.save('my_model', save_format='tf')\n",
    "\n",
    "        all_pred_labels = []\n",
    "        all_true_labels = []\n",
    "        total_loss = 0\n",
    "        for inputs, labels in self.valloader:\n",
    "            outputs = self.model.predict(inputs,verbose=0)\n",
    "            loss = self.loss_fxn(labels, outputs)\n",
    "\n",
    "            # Store predictions and true labels\n",
    "            pred_labels = tf.argmax(outputs, axis=-1).numpy()\n",
    "            all_pred_labels.extend(pred_labels)\n",
    "            all_true_labels.extend(labels.numpy())\n",
    "\n",
    "            # Accumulate the total loss\n",
    "            total_loss += loss.numpy()\n",
    "       \n",
    "        all_pred_labels = np.array(all_pred_labels).flatten()\n",
    "        all_true_labels = np.array(all_true_labels).flatten()\n",
    "        print(all_true_labels.shape)\n",
    "        print(all_pred_labels.shape)\n",
    "        # Calculate metrics\n",
    "        precision = precision_score(all_true_labels, all_pred_labels, average='weighted', labels=np.unique(all_pred_labels))\n",
    "        recall = recall_score(all_true_labels, all_pred_labels, average='weighted', labels=np.unique(all_pred_labels))\n",
    "        f1 = f1_score(all_true_labels, all_pred_labels, average='weighted', labels=np.unique(all_pred_labels))\n",
    "        accuracy = accuracy_score(all_true_labels, all_pred_labels)\n",
    "        average_loss = total_loss / len(self.valloader)\n",
    "\n",
    "        # Register metrics\n",
    "        register_metrics(\n",
    "                    self.inp_data['LR'],\n",
    "                    self.inp_data['batch_size'],\n",
    "                    self.inp_data['epochs'],\n",
    "                    epoch,\n",
    "                    self.inp_data['mixed_memory'],\n",
    "                    self.inp_data['go_backwards'],\n",
    "                    self.inp_data['stateful'],\n",
    "                    self.inp_data['units'],\n",
    "                    self.inp_data['backbone_units'],\n",
    "                    self.inp_data['backbone_layers'],\n",
    "                    self.inp_data['backbone_dropout'],\n",
    "                    average_loss,\n",
    "                    accuracy,\n",
    "                    precision,\n",
    "                    f1,\n",
    "                    recall\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a449d658",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_test(LR=0.0001, epochs=10, \n",
    "             units=4, \n",
    "             mixed_memory=False, \n",
    "             go_backwards=False, \n",
    "             stateful=False,\n",
    "             backbone_units=128, \n",
    "             backbone_layers=1, \n",
    "             backbone_dropout=0,\n",
    "             batch_size = 32):\n",
    "   \n",
    "    \n",
    "    env = gym.make(\"ALE/Breakout-v5\")\n",
    "    env = wrap_deepmind(env)\n",
    "\n",
    "    data = AtariCloningDatasetTF(\"breakout\")\n",
    "    trainloader = data.get_dataset(batch_size, split=\"train\")\n",
    "    valloader = data.get_dataset(batch_size, split=\"val\")\n",
    "\n",
    "    model = ConvCFC(env.action_space.n, units=units, mixed_memory=mixed_memory, go_backwards=go_backwards,\n",
    "                    stateful=stateful, backbone_units=backbone_units, backbone_layers=backbone_layers,\n",
    "                    backbone_dropout=backbone_dropout)\n",
    "    loss_fxn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(\n",
    "        loss=loss_fxn,\n",
    "        optimizer=tf.keras.optimizers.Adam(LR),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    model.build((None, None, 84, 84, 4))\n",
    "\n",
    "    inp_data = {\n",
    "        'batch_size':batch_size,\n",
    "        'epochs':epochs,\n",
    "        'LR':LR,\n",
    "        'units':units,\n",
    "        'mixed_memory':mixed_memory,\n",
    "        'go_backwards':go_backwards,\n",
    "        'stateful':stateful,\n",
    "        'backbone_units':backbone_units,\n",
    "        'backbone_layers':backbone_layers,\n",
    "        'backbone_dropout':backbone_dropout\n",
    "    }\n",
    "    model.summary()\n",
    "    model.fit(\n",
    "        trainloader,\n",
    "        epochs=epochs,\n",
    "        validation_data=valloader,\n",
    "        # callbacks=[ClosedLoopCallback(model, env)],\n",
    "        callbacks=[EvalCSVCallback(model,valloader=valloader,inp_data=inp_data,loss_fxn = loss_fxn)],\n",
    "    )\n",
    "    \n",
    "    visualize(model)\n",
    "\n",
    "\n",
    "\n",
    "def visualize(model):\n",
    "    # Visualize Atari game and play endlessly\n",
    "    # env = gymnasium.make(\"ALE/Breakout-v5\", render_mode=\"human\")\n",
    "    env = gym.make(\"ALE/Breakout-v5\", render_mode=\"human\")\n",
    "    env = wrap_deepmind(env)\n",
    "    run_closed_loop(model, env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a6125aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 21:41:26,003\tWARNING deprecation.py:47 -- DeprecationWarning: `FrameStack` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\vishn\\miniconda3\\envs\\liquid\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\vishn\\miniconda3\\envs\\liquid\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\vishn\\miniconda3\\envs\\liquid\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:189: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\vishn\\miniconda3\\envs\\liquid\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:189: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\vishn\\miniconda3\\envs\\liquid\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\vishn\\miniconda3\\envs\\liquid\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"conv_ltc\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " impala_conv_block (ImpalaC  (None, 256)               423488    \n",
      " onvBlock)                                                       \n",
      "                                                                 \n",
      " time_distributed (TimeDist  multiple                  423488    \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " cf_c (CfC)                  multiple                  33540     \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 457036 (1.74 MB)\n",
      "Trainable params: 456876 (1.74 MB)\n",
      "Non-trainable params: 160 (640.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\vishn\\miniconda3\\envs\\liquid\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\vishn\\miniconda3\\envs\\liquid\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9/938 [..............................] - ETA: 20:50 - loss: 1.2479 - sparse_categorical_accuracy: 0.7701"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# running tests\n",
    "\n",
    "for LR in [0.1,0.01]:\n",
    "    t = time.time()\n",
    "    run_test(epochs=5,units=4,LR=LR)\n",
    "    print(f\"\\n\\n\\n\\ntest time :-{time.time()-t}\\n\\n\\n\\n\")\n",
    "\n",
    "\n",
    "for LR in [0.001, 0.00001, 0.000001]:\n",
    "    for b in [16, 64, 128]:\n",
    "        for backbone_units in (64,128,256):\n",
    "            for backbone_layers in (1,2):\n",
    "                t = time.time()\n",
    "                run_test(epochs=5,units=4,batch_size=b,LR=LR,backbone_layers=backbone_layers,backbone_units=backbone_units)\n",
    "                print(f\"\\n\\n\\n\\ntest time :-{time.time()-t}\\n\\n\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
